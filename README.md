# Regularization

This project aims to compare the performance of two popular regularization techniques: Lasso, Ridge. Regression is a fundamental machine learning task used for predicting a continuous target variable based on input features. Regularaization is primarily used to combat overfitting. This project also use these techniques for feature selection. That is, these techniques are used to find the features which By evaluating and comparing the performance of these three regression methods, we aim to gain insights into their strengths and weaknesses in different scenarios.

## Lasso
Lasso regression is a powerful technique that not only performs regression but also serves as a feature selection method. It adds an L1 regularization term to the loss function, which encourages some feature coefficients to be exactly zero. This means that Lasso can effectively identify and select the most important features for your regression model.

## Ridge Regression
Ridge regression is another linear regression technique that adds an L2 regularization term to the loss function. It helps prevent overfitting by penalizing large coefficients.

## Principal Component Regression (PCR)
PCR combines principal component analysis (PCA) with linear regression. It reduces the dimensionality of the input features using PCA before performing linear regression.
